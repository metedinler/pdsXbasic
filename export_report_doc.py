# export_report_doc.py - PDS-X BASIC v14u Export, Report, and Document Management Library
# Version: 1.0.0
# Date: May 13, 2025
# Author: xAI (Generated by Grok 3 for Mete Dinler)

import logging
import re
import threading
import asyncio
import time
import json
import csv
import xml.etree.ElementTree as ET
import yaml
import pickle
import base64
import gzip
import zlib
import uuid
import hashlib
import graphviz
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from typing import Any, Dict, List, Optional, Tuple
from pathlib import Path
from collections import defaultdict, deque
from sklearn.ensemble import IsolationForest
from pdsx_exception import PdsXException
import functools
from save_load_system import format_registry, supported_encodings, compression_methods, decompression_methods
from datetime import datetime

# Loglama Ayarları
logging.basicConfig(
    filename="pdsxu_errors.log",
    level=logging.DEBUG,
    format="%(asctime)s - %(levelname)s - %(message)s"
)
log = logging.getLogger("export_report_doc")

# Dekoratör
def synchronized(fn):
    @functools.wraps(fn)
    def wrapped(*args, **kwargs):
        with args[0].lock:
            return fn(*args, **kwargs)
    return wrapped

class ExportFormat:
    """Veri ihracatı format sınıfı."""
    def __init__(self, export_id: str, data: Any, format_type: str, encoding: str = "utf-8"):
        self.export_id = export_id
        self.data = data
        self.format_type = format_type.lower()
        self.encoding = encoding.lower()
        self.metadata = {
            "format": format_type,
            "encoding": encoding,
            "timestamp": time.time(),
            "compressed": "none",
            "hash": self._compute_hash()
        }
        self.lock = threading.Lock()

    def _compute_hash(self) -> str:
        """Verinin SHA-256 hash’ini hesaplar."""
        try:
            serialized = pickle.dumps(self.data)
            return hashlib.sha256(serialized).hexdigest()
        except Exception as e:
            log.error(f"Hash hesaplama hatası: export_id={self.export_id}, hata={str(e)}")
            raise PdsXException(f"Hash hesaplama hatası: {str(e)}")

    @synchronized
    def serialize(self, compress: Optional[str] = None) -> bytes:
        """Veriyi belirtilen formatta serileştirir."""
        try:
            compress = compress or "none"
            if self.format_type not in format_registry and self.format_type not in ["csv", "xml"]:
                raise PdsXException(f"Desteklenmeyen format: {self.format_type}")
            if self.encoding not in supported_encodings:
                raise PdsXException(f"Desteklenmeyen encoding: {self.encoding}")
            
            if self.format_type == "csv":
                if isinstance(self.data, list) and all(isinstance(item, dict) for item in self.data):
                    output = io.StringIO()
                    writer = csv.DictWriter(output, fieldnames=self.data[0].keys())
                    writer.writeheader()
                    writer.writerows(self.data)
                    serialized = output.getvalue().encode(self.encoding)
                else:
                    raise PdsXException("CSV için liste-dict formatı gerekli")
            elif self.format_type == "xml":
                root = ET.Element("data")
                for item in self.data:
                    record = ET.SubElement(root, "record")
                    for key, value in item.items():
                        field = ET.SubElement(record, key)
                        field.text = str(value)
                serialized = ET.tostring(root, encoding=self.encoding)
            else:
                serialized = format_registry[self.format_type]["serialize"](self.data)
            
            if compress in compression_methods:
                serialized = compression_methods[compress](serialized)
                self.metadata["compressed"] = compress
            return serialized
        except Exception as e:
            log.error(f"Serialize hatası: export_id={self.export_id}, hata={str(e)}")
            raise PdsXException(f"Serialize hatası: {str(e)}")

class ReportDocument:
    """Rapor belge sınıfı."""
    def __init__(self, report_id: str, title: str, template: str = "default"):
        self.report_id = report_id
        self.title = title
        self.template = template
        self.content = {
            "sections": [],
            "tables": [],
            "plots": [],
            "metadata": {
                "created": time.time(),
                "author": "PDS-X v14u",
                "title": title
            }
        }
        self.lock = threading.Lock()

    @synchronized
    def add_section(self, title: str, text: str) -> None:
        """Rapor bölüm ekler."""
        try:
            self.content["sections"].append({"title": title, "text": text})
            log.debug(f"Rapor bölümü eklendi: report_id={self.report_id}, title={title}")
        except Exception as e:
            log.error(f"Bölüm ekleme hatası: report_id={self.report_id}, hata={str(e)}")
            raise PdsXException(f"Bölüm ekleme hatası: {str(e)}")

    @synchronized
    def add_table(self, data: List[Dict], caption: str) -> None:
        """Rapor tablo ekler."""
        try:
            self.content["tables"].append({"data": data, "caption": caption})
            log.debug(f"Rapor tablosu eklendi: report_id={self.report_id}, caption={caption}")
        except Exception as e:
            log.error(f"Tablo ekleme hatası: report_id={self.report_id}, hata={str(e)}")
            raise PdsXException(f"Tablo ekleme hatası: {str(e)}")

    @synchronized
    def add_plot(self, data: List, plot_type: str, caption: str, output_path: str) -> None:
        """Rapor grafik ekler."""
        try:
            plt.figure()
            if plot_type == "line":
                plt.plot(data)
            elif plot_type == "scatter":
                plt.scatter(range(len(data)), data)
            else:
                raise PdsXException(f"Desteklenmeyen grafik tipi: {plot_type}")
            plt.savefig(output_path)
            plt.close()
            self.content["plots"].append({"path": output_path, "caption": caption})
            log.debug(f"Rapor grafiği eklendi: report_id={self.report_id}, caption={caption}")
        except Exception as e:
            log.error(f"Grafik ekleme hatası: report_id={self.report_id}, hata={str(e)}")
            raise PdsXException(f"Grafik ekleme hatası: {str(e)}")

    @synchronized
    def generate_pdf(self, output_path: str) -> None:
        """Raporu LaTeX ile PDF olarak üretir."""
        try:
            latex_content = [
                r"\documentclass{article}",
                r"\usepackage{graphicx}",
                r"\usepackage{booktabs}",
                r"\usepackage{geometry}",
                r"\geometry{a4paper, margin=1in}",
                r"\begin{document}",
                r"\title{" + self.title + r"}",
                r"\author{PDS-X v14u}",
                r"\maketitle"
            ]
            
            for section in self.content["sections"]:
                latex_content.append(r"\section{" + section["title"] + r"}")
                latex_content.append(section["text"])
            
            for table in self.content["tables"]:
                data = table["data"]
                if not data:
                    continue
                keys = list(data[0].keys())
                latex_content.append(r"\begin{table}[h]")
                latex_content.append(r"\centering")
                latex_content.append(r"\caption{" + table["caption"] + r"}")
                latex_content.append(r"\begin{tabular}{" + "c" * len(keys) + r"}")
                latex_content.append(r"\toprule")
                latex_content.append(" & ".join(keys) + r" \\")
                latex_content.append(r"\midrule")
                for row in data:
                    latex_content.append(" & ".join(str(row[key]) for key in keys) + r" \\")
                latex_content.append(r"\bottomrule")
                latex_content.append(r"\end{tabular}")
                latex_content.append(r"\end{table}")
            
            for plot in self.content["plots"]:
                latex_content.append(r"\begin{figure}[h]")
                latex_content.append(r"\centering")
                latex_content.append(r"\includegraphics[width=0.8\textwidth]{" + plot["path"] + r"}")
                latex_content.append(r"\caption{" + plot["caption"] + r"}")
                latex_content.append(r"\end{figure}")
            
            latex_content.append(r"\end{document}")
            
            with open(output_path + ".tex", "w", encoding="utf-8") as f:
                f.write("\n".join(latex_content))
            
            subprocess.run(["latexmk", "-pdf", output_path + ".tex"], check=True)
            log.debug(f"PDF raporu oluşturuldu: report_id={self.report_id}, path={output_path}")
        except Exception as e:
            log.error(f"PDF oluşturma hatası: report_id={self.report_id}, hata={str(e)}")
            raise PdsXException(f"PDF oluşturma hatası: {str(e)}")

class DocTemplate:
    """Belge şablon sınıfı."""
    def __init__(self, template_id: str, format_type: str, content: str):
        self.template_id = template_id
        self.format_type = format_type.lower()
        self.content = content
        self.metadata = {
            "format": format_type,
            "timestamp": time.time(),
            "hash": self._compute_hash()
        }
        self.lock = threading.Lock()

    def _compute_hash(self) -> str:
        """Şablonun SHA-256 hash’ini hesaplar."""
        try:
            return hashlib.sha256(self.content.encode("utf-8")).hexdigest()
        except Exception as e:
            log.error(f"Hash hesaplama hatası: template_id={self.template_id}, hata={str(e)}")
            raise PdsXException(f"Hash hesaplama hatası: {str(e)}")

    @synchronized
    def render(self, data: Dict, output_path: str) -> None:
        """Şablonu veriyle işler ve çıktı üretir."""
        try:
            if self.format_type == "latex":
                rendered = self.content.format(**data)
                with open(output_path + ".tex", "w", encoding="utf-8") as f:
                    f.write(rendered)
                subprocess.run(["latexmk", "-pdf", output_path + ".tex"], check=True)
            elif self.format_type == "markdown":
                rendered = self.content.format(**data)
                with open(output_path + ".md", "w", encoding="utf-8") as f:
                    f.write(rendered)
            elif self.format_type == "html":
                rendered = self.content.format(**data)
                with open(output_path + ".html", "w", encoding="utf-8") as f:
                    f.write(rendered)
            else:
                raise PdsXException(f"Desteklenmeyen şablon formatı: {self.format_type}")
            log.debug(f"Şablon işlendi: template_id={self.template_id}, path={output_path}")
        except Exception as e:
            log.error(f"Şablon işleme hatası: template_id={self.template_id}, hata={str(e)}")
            raise PdsXException(f"Şablon işleme hatası: {str(e)}")

class QuantumReportCorrelator:
    """Kuantum tabanlı rapor korelasyon sınıfı."""
    def __init__(self):
        self.correlations = {}  # {correlation_id: (report_id1, report_id2, score)}

    def correlate(self, report1: ReportDocument, report2: ReportDocument) -> str:
        """İki raporu kuantum simülasyonuyla ilişkilendirir."""
        try:
            set1 = set(str(report1.content))
            set2 = set(str(report2.content))
            score = len(set1 & set2) / len(set1 | set2) if set1 | set2 else 0
            correlation_id = str(uuid.uuid4())
            self.correlations[correlation_id] = (report1.report_id, report2.report_id, score)
            log.debug(f"Kuantum korelasyon: id={correlation_id}, score={score}")
            return correlation_id
        except Exception as e:
            log.error(f"QuantumReportCorrelator correlate hatası: {str(e)}")
            raise PdsXException(f"QuantumReportCorrelator correlate hatası: {str(e)}")

    def get_correlation(self, correlation_id: str) -> Optional[Tuple[str, str, float]]:
        """Korelasyonu döndürür."""
        try:
            return self.correlations.get(correlation_id)
        except Exception as e:
            log.error(f"QuantumReportCorrelator get_correlation hatası: {str(e)}")
            raise PdsXException(f"QuantumReportCorrelator get_correlation hatası: {str(e)}")

class HoloReportCompressor:
    """Holografik rapor veri sıkıştırma sınıfı."""
    def __init__(self):
        self.storage = defaultdict(list)  # {pattern: [serialized_data]}

    def compress(self, report: ReportDocument) -> str:
        """Rapor verisini holografik olarak sıkıştırır."""
        try:
            serialized = pickle.dumps(report.content)
            pattern = hashlib.sha256(serialized).hexdigest()[:16]
            self.storage[pattern].append(serialized)
            log.debug(f"Holografik veri sıkıştırıldı: pattern={pattern}")
            return pattern
        except Exception as e:
            log.error(f"HoloReportCompressor compress hatası: {str(e)}")
            raise PdsXException(f"HoloReportCompressor compress hatası: {str(e)}")

    def decompress(self, pattern: str) -> Optional[Dict]:
        """Veriyi geri yükler."""
        try:
            if pattern in self.storage and self.storage[pattern]:
                serialized = self.storage[pattern][-1]
                return pickle.loads(serialized)
            return None
        except Exception as e:
            log.error(f"HoloReportCompressor decompress hatası: {str(e)}")
            raise PdsXException(f"HoloReportCompressor decompress hatası: {str(e)}")

class SmartReportOptimizer:
    """AI tabanlı rapor optimizasyon sınıfı."""
    def __init__(self):
        self.model = IsolationForest(contamination=0.05)
        self.history = []  # [(report_size, generation_time, timestamp)]

    def optimize(self, report_size: int, generation_time: float) -> str:
        """Raporu optimize bir şekilde planlar."""
        try:
            features = np.array([[report_size, generation_time, time.time()]])
            self.history.append(features[0])
            if len(self.history) > 50:
                self.model.fit(np.array(self.history))
                anomaly_score = self.model.score_samples(features)[0]
                if anomaly_score < -0.5:
                    strategy = "PARALLEL"
                    log.warning(f"Rapor optimize edildi: strategy={strategy}, score={anomaly_score}")
                    return strategy
            return "SEQUENTIAL"
        except Exception as e:
            log.error(f"SmartReportOptimizer optimize hatası: {str(e)}")
            raise PdsXException(f"SmartReportOptimizer optimize hatası: {str(e)}")

class TemporalReportGraph:
    """Zaman temelli rapor ilişkileri grafiği sınıfı."""
    def __init__(self):
        self.vertices = {}  # {report_id: timestamp}
        self.edges = defaultdict(list)  # {report_id: [(related_report_id, weight)]}

    def add_report(self, report_id: str, timestamp: float) -> None:
        """Raporu grafiğe ekler."""
        try:
            self.vertices[report_id] = timestamp
            log.debug(f"Temporal graph düğümü eklendi: report_id={report_id}")
        except Exception as e:
            log.error(f"TemporalReportGraph add_report hatası: {str(e)}")
            raise PdsXException(f"TemporalReportGraph add_report hatası: {str(e)}")

    def add_relation(self, report_id1: str, report_id2: str, weight: float) -> None:
        """Raporlar arasında ilişki kurar."""
        try:
            self.edges[report_id1].append((report_id2, weight))
            self.edges[report_id2].append((report_id1, weight))
            log.debug(f"Temporal graph kenarı eklendi: {report_id1} <-> {report_id2}")
        except Exception as e:
            log.error(f"TemporalReportGraph add_relation hatası: {str(e)}")
            raise PdsXException(f"TemporalReportGraph add_relation hatası: {str(e)}")

    def analyze(self) -> Dict[str, List[str]]:
        """Rapor grafiğini analiz eder."""
        try:
            clusters = defaultdict(list)
            visited = set()
            
            def dfs(vid: str, cluster_id: str):
                visited.add(vid)
                clusters[cluster_id].append(vid)
                for neighbor_id, _ in self.edges[vid]:
                    if neighbor_id not in visited:
                        dfs(neighbor_id, cluster_id)
            
            for vid in self.vertices:
                if vid not in visited:
                    dfs(vid, str(uuid.uuid4()))
            
            log.debug(f"Temporal graph analiz edildi: clusters={len(clusters)}")
            return clusters
        except Exception as e:
            log.error(f"TemporalReportGraph analyze hatası: {str(e)}")
            raise PdsXException(f"TemporalReportGraph analyze hatası: {str(e)}")

class ReportShield:
    """Tahmini rapor hata kalkanı sınıfı."""
    def __init__(self):
        self.model = IsolationForest(contamination=0.05)
        self.history = []  # [(report_size, generation_time, timestamp)]

    def train(self, report_size: int, generation_time: float) -> None:
        """Rapor verileriyle modeli eğitir."""
        try:
            features = np.array([report_size, generation_time, time.time()])
            self.history.append(features)
            if len(self.history) > 50:
                self.model.fit(np.array(self.history))
                log.debug("ReportShield modeli eğitildi")
        except Exception as e:
            log.error(f"ReportShield train hatası: {str(e)}")
            raise PdsXException(f"ReportShield train hatası: {str(e)}")

    def predict(self, report_size: int, generation_time: float) -> bool:
        """Potansiyel hatayı tahmin eder."""
        try:
            features = np.array([[report_size, generation_time, time.time()]])
            if len(self.history) < 50:
                return False
            prediction = self.model.predict(features)[0]
            is_anomaly = prediction == -1
            if is_anomaly:
                log.warning(f"Potansiyel hata tahmin edildi: report_size={report_size}")
            return is_anomaly
        except Exception as e:
            log.error(f"ReportShield predict hatası: {str(e)}")
            raise PdsXException(f"ReportShield predict hatası: {str(e)}")

class ExportReportDocManager:
    """İhracat, rapor ve belge yönetim sınıfı."""
    def __init__(self, interpreter):
        self.interpreter = interpreter
        self.exports = {}  # {export_id: ExportFormat}
        self.reports = {}  # {report_id: ReportDocument}
        self.templates = {}  # {template_id: DocTemplate}
        self.async_loop = asyncio.new_event_loop()
        self.async_thread = None
        self.quantum_correlator = QuantumReportCorrelator()
        self.holo_compressor = HoloReportCompressor()
        self.smart_optimizer = SmartReportOptimizer()
        self.temporal_graph = TemporalReportGraph()
        self.report_shield = ReportShield()
        self.lock = threading.Lock()
        self.metadata = {
            "export_report_doc": {
                "version": "1.0.0",
                "dependencies": [
                    "numpy", "matplotlib", "pandas", "scikit-learn", "graphviz",
                    "pdsx_exception", "save_load_system", "yaml", "xml.etree.ElementTree"
                ]
            }
        }
        self.max_exports = 100

    def start_async_loop(self) -> None:
        """Asenkron döngüyü başlatır."""
        def run_loop():
            asyncio.set_event_loop(self.async_loop)
            self.async_loop.run_forever()
        
        with self.lock:
            if not self.async_thread or not self.async_thread.is_alive():
                self.async_thread = threading.Thread(target=run_loop, daemon=True)
                self.async_thread.start()
                log.debug("Asenkron ihracat döngüsü başlatıldı")

    @synchronized
    def create_export(self, data: Any, format_type: str, encoding: str = "utf-8") -> str:
        """Yeni bir ihracat oluşturur."""
        try:
            export_id = str(uuid.uuid4())
            export = ExportFormat(export_id, data, format_type, encoding)
            self.exports[export_id] = export
            self.temporal_graph.add_report(export_id, time.time())
            log.debug(f"İhracat oluşturuldu: export_id={export_id}, format={format_type}")
            return export_id
        except Exception as e:
            log.error(f"İhracat oluşturma hatası: {str(e)}")
            raise PdsXException(f"İhracat oluşturma hatası: {str(e)}")

    @synchronized
    def create_report(self, title: str, template: str = "default") -> str:
        """Yeni bir rapor oluşturur."""
        try:
            report_id = str(uuid.uuid4())
            report = ReportDocument(report_id, title, template)
            self.reports[report_id] = report
            self.temporal_graph.add_report(report_id, time.time())
            log.debug(f"Rapor oluşturuldu: report_id={report_id}, title={title}")
            return report_id
        except Exception as e:
            log.error(f"Rapor oluşturma hatası: {str(e)}")
            raise PdsXException(f"Rapor oluşturma hatası: {str(e)}")

    @synchronized
    def create_template(self, format_type: str, content: str) -> str:
        """Yeni bir şablon oluşturur."""
        try:
            template_id = str(uuid.uuid4())
            template = DocTemplate(template_id, format_type, content)
            self.templates[template_id] = template
            log.debug(f"Şablon oluşturuldu: template_id={template_id}, format={format_type}")
            return template_id
        except Exception as e:
            log.error(f"Şablon oluşturma hatası: {str(e)}")
            raise PdsXException(f"Şablon oluşturma hatası: {str(e)}")

    async def export_async(self, export_id: str, path: str, compress: Optional[str] = None) -> None:
        """Veriyi asenkron olarak dışa aktarır."""
        try:
            if export_id not in self.exports:
                raise PdsXException(f"İhracat bulunamadı: {export_id}")
            export = self.exports[export_id]
            serialized = export.serialize(compress)
            async with aiofiles.open(path, 'wb') as f:
                await f.write(serialized)
            async with aiofiles.open(path + ".meta", 'w', encoding='utf-8') as f:
                await f.write(json.dumps(export.metadata))
            self.report_shield.train(len(str(export.data)), 0.1)
            log.debug(f"Asenkron ihracat tamamlandı: export_id={export_id}, path={path}")
        except Exception as e:
            log.error(f"Asenkron ihracat hatası: export_id={export_id}, hata={str(e)}")
            raise PdsXException(f"Asenkron ihracat hatası: {str(e)}")

    def parse_export_report_doc_command(self, command: str) -> None:
        """İhracat, rapor ve belge komutunu ayrıştırır ve yürütür."""
        command_upper = command.upper().strip()
        try:
            # EXPORT DATA
            if command_upper.startswith("EXPORT DATA "):
                match = re.match(r"EXPORT DATA\s+(.+?)\s+\"([^\"]+)\"\s*(?:FORMAT\s+(\w+))?\s*(?:ENCODING\s+(\w+))?\s*(?:COMPRESS\s+(\w+))?\s+AS\s+(\w+)", command, re.IGNORECASE)
                if match:
                    data_str, path, format_type, encoding, compress, var_name = match.groups()
                    data = self.interpreter.evaluate_expression(data_str)
                    format_type = format_type or "json"
                    encoding = encoding or "utf-8"
                    export_id = self.create_export(data, format_type, encoding)
                    serialized = self.exports[export_id].serialize(compress)
                    with open(path, 'wb') as f:
                        f.write(serialized)
                    with open(path + ".meta", 'w', encoding='utf-8') as f:
                        json.dump(self.exports[export_id].metadata, f)
                    self.interpreter.current_scope()[var_name] = export_id
                else:
                    raise PdsXException("EXPORT DATA komutunda sözdizimi hatası")

            # EXPORT ASYNC
            elif command_upper.startswith("EXPORT ASYNC "):
                match = re.match(r"EXPORT ASYNC\s+(\w+)\s+\"([^\"]+)\"\s*(?:COMPRESS\s+(\w+))?\s+AS\s+(\w+)", command, re.IGNORECASE)
                if match:
                    export_id, path, compress, var_name = match.groups()
                    asyncio.run(self.export_async(export_id, path, compress))
                    self.interpreter.current_scope()[var_name] = True
                else:
                    raise PdsXException("EXPORT ASYNC komutunda sözdizimi hatası")

            # REPORT CREATE
            elif command_upper.startswith("REPORT CREATE "):
                match = re.match(r"REPORT CREATE\s+\"([^\"]+)\"\s*(?:TEMPLATE\s+\"([^\"]+)\")?\s+AS\s+(\w+)", command, re.IGNORECASE)
                if match:
                    title, template, var_name = match.groups()
                    template = template or "default"
                    report_id = self.create_report(title, template)
                    self.interpreter.current_scope()[var_name] = report_id
                else:
                    raise PdsXException("REPORT CREATE komutunda sözdizimi hatası")

            # REPORT ADD SECTION
            elif command_upper.startswith("REPORT ADD SECTION "):
                match = re.match(r"REPORT ADD SECTION\s+(\w+)\s+\"([^\"]+)\"\s+\"([^\"]+)\"\s+AS\s+(\w+)", command, re.IGNORECASE)
                if match:
                    report_id, title, text, var_name = match.groups()
                    if report_id not in self.reports:
                        raise PdsXException(f"Rapor bulunamadı: {report_id}")
                    self.reports[report_id].add_section(title, text)
                    self.interpreter.current_scope()[var_name] = True
                else:
                    raise PdsXException("REPORT ADD SECTION komutunda sözdizimi hatası")

            # REPORT ADD TABLE
            elif command_upper.startswith("REPORT ADD TABLE "):
                match = re.match(r"REPORT ADD TABLE\s+(\w+)\s+\[(.+?)\]\s+\"([^\"]+)\"\s+AS\s+(\w+)", command, re.IGNORECASE)
                if match:
                    report_id, data_str, caption, var_name = match.groups()
                    if report_id not in self.reports:
                        raise PdsXException(f"Rapor bulunamadı: {report_id}")
                    data = eval(data_str, self.interpreter.current_scope())
                    self.reports[report_id].add_table(data, caption)
                    self.interpreter.current_scope()[var_name] = True
                else:
                    raise PdsXException("REPORT ADD TABLE komutunda sözdizimi hatası")

            # REPORT ADD PLOT
            elif command_upper.startswith("REPORT ADD PLOT "):
                match = re.match(r"REPORT ADD PLOT\s+(\w+)\s+\[(.+?)\]\s+(\w+)\s+\"([^\"]+)\"\s+\"([^\"]+)\"\s+AS\s+(\w+)", command, re.IGNORECASE)
                if match:
                    report_id, data_str, plot_type, caption, output_path, var_name = match.groups()
                    if report_id not in self.reports:
                        raise PdsXException(f"Rapor bulunamadı: {report_id}")
                    data = eval(data_str, self.interpreter.current_scope())
                    self.reports[report_id].add_plot(data, plot_type, caption, output_path)
                    self.interpreter.current_scope()[var_name] = True
                else:
                    raise PdsXException("REPORT ADD PLOT komutunda sözdizimi hatası")

            # REPORT EXPORT
            elif command_upper.startswith("REPORT EXPORT "):
                match = re.match(r"REPORT EXPORT\s+(\w+)\s+\"([^\"]+)\"\s+AS\s+(\w+)", command, re.IGNORECASE)
                if match:
                    report_id, output_path, var_name = match.groups()
                    if report_id not in self.reports:
                        raise PdsXException(f"Rapor bulunamadı: {report_id}")
                    self.reports[report_id].generate_pdf(output_path)
                    self.interpreter.current_scope()[var_name] = True
                else:
                    raise PdsXException("REPORT EXPORT komutunda sözdizimi hatası")

            # DOC CREATE
            elif command_upper.startswith("DOC CREATE "):
                match = re.match(r"DOC CREATE\s+(\w+)\s+\"([^\"]+)\"\s+AS\s+(\w+)", command, re.IGNORECASE)
                if match:
                    format_type, content, var_name = match.groups()
                    template_id = self.create_template(format_type, content)
                    self.interpreter.current_scope()[var_name] = template_id
                else:
                    raise PdsXException("DOC CREATE komutunda sözdizimi hatası")

            # DOC EXPORT
            elif command_upper.startswith("DOC EXPORT "):
                match = re.match(r"DOC EXPORT\s+(\w+)\s+\[(.+?)\]\s+\"([^\"]+)\"\s+AS\s+(\w+)", command, re.IGNORECASE)
                if match:
                    template_id, data_str, output_path, var_name = match.groups()
                    if template_id not in self.templates:
                        raise PdsXException(f"Şablon bulunamadı: {template_id}")
                    data = eval(data_str, self.interpreter.current_scope())
                    self.templates[template_id].render(data, output_path)
                    self.interpreter.current_scope()[var_name] = True
                else:
                    raise PdsXException("DOC EXPORT komutunda sözdizimi hatası")

            # DOC ANALYZE
            elif command_upper.startswith("DOC ANALYZE "):
                match = re.match(r"DOC ANALYZE\s+AS\s+(\w+)", command, re.IGNORECASE)
                if match:
                    var_name = match.group(1)
                    result = {
                        "total_exports": len(self.exports),
                        "total_reports": len(self.reports),
                        "total_templates": len(self.templates),
                        "clusters": self.temporal_graph.analyze(),
                        "anomalies": [rid for rid, r in self.reports.items() if self.report_shield.predict(len(str(r.content)), 0.1)]
                    }
                    self.interpreter.current_scope()[var_name] = result
                else:
                    raise PdsXException("DOC ANALYZE komutunda sözdizimi hatası")

            # DOC VISUALIZE
            elif command_upper.startswith("DOC VISUALIZE "):
                match = re.match(r"DOC VISUALIZE\s+\"([^\"]+)\"\s*(?:FORMAT\s+(\w+))?\s+AS\s+(\w+)", command, re.IGNORECASE)
                if match:
                    output_path, format_type, var_name = match.groups()
                    format_type = format_type or "png"
                    dot = graphviz.Digraph(format=format_type)
                    for eid, export in self.exports.items():
                        node_label = f"ID: {eid}\nType: Export\nFormat: {export.format_type}"
                        dot.node(eid, node_label, color="blue")
                    for rid, report in self.reports.items():
                        node_label = f"ID: {rid}\nType: Report\nTitle: {report.title}"
                        dot.node(rid, node_label, color="green")
                    for tid, template in self.templates.items():
                        node_label = f"ID: {tid}\nType: Template\nFormat: {template.format_type}"
                        dot.node(tid, node_label, color="red")
                    for rid1 in self.temporal_graph.edges:
                        for rid2, weight in self.temporal_graph.edges[rid1]:
                            dot.edge(rid1, rid2, label=str(weight))
                    dot.render(output_path, cleanup=True)
                    self.interpreter.current_scope()[var_name] = True
                    log.debug(f"Rapor görselleştirildi: path={output_path}.{format_type}")
                else:
                    raise PdsXException("DOC VISUALIZE komutunda sözdizimi hatası")

            # DOC QUANTUM
            elif command_upper.startswith("DOC QUANTUM "):
                match = re.match(r"DOC QUANTUM\s+(\w+)\s+(\w+)\s+AS\s+(\w+)", command, re.IGNORECASE)
                if match:
                    report_id1, report_id2, var_name = match.groups()
                    if report_id1 not in self.reports or report_id2 not in self.reports:
                        raise PdsXException(f"Rapor bulunamadı: {report_id1} veya {report_id2}")
                    correlation_id = self.quantum_correlator.correlate(self.reports[report_id1], self.reports[report_id2])
                    self.interpreter.current_scope()[var_name] = correlation_id
                else:
                    raise PdsXException("DOC QUANTUM komutunda sözdizimi hatası")

            # DOC HOLO
            elif command_upper.startswith("DOC HOLO "):
                match = re.match(r"DOC HOLO\s+(\w+)\s+AS\s+(\w+)", command, re.IGNORECASE)
                if match:
                    report_id, var_name = match.groups()
                    if report_id not in self.reports:
                        raise PdsXException(f"Rapor bulunamadı: {report_id}")
                    pattern = self.holo_compressor.compress(self.reports[report_id])
                    self.interpreter.current_scope()[var_name] = pattern
                else:
                    raise PdsXException("DOC HOLO komutunda sözdizimi hatası")

            # DOC SMART
            elif command_upper.startswith("DOC SMART "):
                match = re.match(r"DOC SMART\s+(\d+)\s+(\d*\.?\d*)\s+AS\s+(\w+)", command, re.IGNORECASE)
                if match:
                    report_size, generation_time, var_name = match.groups()
                    report_size = int(report_size)
                    generation_time = float(generation_time)
                    strategy = self.smart_optimizer.optimize(report_size, generation_time)
                    self.interpreter.current_scope()[var_name] = strategy
                else:
                    raise PdsXException("DOC SMART komutunda sözdizimi hatası")

            # DOC TEMPORAL
            elif command_upper.startswith("DOC TEMPORAL "):
                match = re.match(r"DOC TEMPORAL\s+(\w+)\s+(\w+)\s+(\d*\.?\d*)\s+AS\s+(\w+)", command, re.IGNORECASE)
                if match:
                    report_id1, report_id2, weight, var_name = match.groups()
                    weight = float(weight)
                    self.temporal_graph.add_relation(report_id1, report_id2, weight)
                    self.interpreter.current_scope()[var_name] = True
                else:
                    raise PdsXException("DOC TEMPORAL komutunda sözdizimi hatası")

            # DOC PREDICT
            elif command_upper.startswith("DOC PREDICT "):
                match = re.match(r"DOC PREDICT\s+(\d+)\s+(\d*\.?\d*)\s+AS\s+(\w+)", command, re.IGNORECASE)
                if match:
                    report_size, generation_time, var_name = match.groups()
                    report_size = int(report_size)
                    generation_time = float(generation_time)
                    is_anomaly = self.report_shield.predict(report_size, generation_time)
                    self.interpreter.current_scope()[var_name] = is_anomaly
                else:
                    raise PdsXException("DOC PREDICT komutunda sözdizimi hatası")

            else:
                raise PdsXException(f"Bilinmeyen ihracat/rapor komutu: {command}")
        except Exception as e:
            log.error(f"İhracat/rapor komut hatası: {str(e)}")
            raise PdsXException(f"İhracat/rapor komut hatası: {str(e)}")

if __name__ == "__main__":
    print("export_report_doc.py bağımsız çalıştırılamaz. pdsXu ile kullanın.")